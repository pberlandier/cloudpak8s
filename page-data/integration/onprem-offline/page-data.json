{"componentChunkName":"component---src-pages-integration-onprem-offline-index-mdx","path":"/integration/onprem-offline/","result":{"pageContext":{"frontmatter":{"title":"VMware using Offline Images","weight":400},"relativePagePath":"/integration/onprem-offline/index.mdx","titleType":"page","MdxNode":{"id":"df44a2b3-9e4c-5e1d-a222-7ac11258d191","children":[],"parent":"6cc8ac23-6c6a-5d5a-848c-416c62cf0f8d","internal":{"content":"---\ntitle: VMware using Offline Images\nweight: 400\n---\n\n- [Setting the max_map_count](#setting-the-max_map_count)\n- [Download and extract the image](#download-and-extract-the-image)\n- [Creating config.yaml](#creating-configyaml)\n- [Creating getAllRec.sh](#creating-getallrecsh)\n- [Starting the install process](#starting-the-install-process)\n- [Creating the correct kubeconfig](#creating-the-correct-kubeconfig)\n- [Uninstalling Common Services](#uninstalling-common-services)\n\n**NOTE: Make sure you have 200GB or more on your installer node. If you have less, then you can download the offline image, extract and delete the original file**\n\n## Setting the max_map_count\n\nSSH into all your worker and storage nodes and set the max_map_count to 262144.\n\n```bash\nsudo sysctl -w vm.max_map_count=262144\necho \"vm.max_map_count=262144\" | sudo tee -a /etc/sysctl.conf\n```\n\n## Download and extract the image\n\nSSH into your installer node. Go to `/opt` dir and download the image there. To download the image from IBM XL, use this <https://w3-03.ibm.com/software/xl/download/ticket.wss>. If in the csplab environment, CP4I 2019.4.1 is already downloaded on the csplab jump server, we'll `wget` from there as it's much faster.\n\n```bash\ncd /opt\nwget http://storage4.csplab.local/storage/cp4i/ibm-cp-int-2019.4.1-offline.tar.gz\nmkdir cp4ioffline\ntar xf ibm-cp-int-2019.4.1-offline.tar.gz --directory /opt/cp4ioffline\ncd cp4ioffline\ntar xvf installer_files/cluster/images/common-services-armonk-x86_64.tar.gz -O | sudo docker load\n```\n\nyou can delete `ibm-cp-int-2019.4.1-offline.tar.gz` now if you're low on space.\n\n## Creating config.yaml\n\nFind your oauth route. Run the following command to find it.\n\n```bash\n$ oc get routes --all-namespaces | grep oauth\nopenshift-authentication   oauth-openshift     oauth-openshift.apps.mislam.ocp.csplab.local\n```\n\nGet the config.yaml from here: https://github.ibm.com/cpat/cp4-integration/blob/master/infra/helper-scripts/config.yaml\n\nCreate a backup of the default `config.yaml` inside of `/opt/cp4ioffline/installer_files/cluster` and paste in your oauth route in the following part of your `config.yaml`:\n\n```yaml\nroks_enabled: true\nroks_url: https://oauth-openshift.apps.mnb.ocp.csplab.local -> your oauth route\nroks_user_prefix: \"\"\n```\n\n## Creating getAllRec.sh\n\nWhen the installer fails, this script will echo all the pods that are up and running and pods that are failing.\n\n```bash\ncd /opt\ntouch getAllRec.sh\nsudo chmod 755 getAllRec.sh\n./getAllRec.sh kube-system\n```\n\nGet the getAllRec.sh file from here: https://github.ibm.com/cpat/cp4-integration/blob/master/infra/helper-scripts/getAllRec.sh\n\n## Creating the correct kubeconfig\n\nFirst we have to copy our kubeconfig to the cluster directory. \n\n```bash\ncd /opt/cp4ioffline/installer_files/cluster\noc config view > kubeconfig\n```\n\nNow `cat` your kubeconfig file and see if it has `insecure-skip-tls-verify: true`config. The cluster part should look something like this.\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://api.mislam.ocp.csplab.local:6443\n  name: api-mislam-ocp-csplab-local:6443\n```\n\nBut if you see this, you have to replace `certificate-authority-data: DATA+OMITTED` with `insecure-skip-tls-verify: true`\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: DATA+OMITTED\n    server: https://api.mislam.ocp.csplab.local:6443\n```\n\nAlternatively we can copy it from our Openshift Cluster Auth directory to here. \n\n```bash\ncp /opt/myocpcluster/auth/kubeconfig /opt/cp4ioffline/installer_files/cluster\n```\n\n## Starting the install process\n\nNow we run the installer. Notice it's a nohup job (runs on the background) and the logs are written to `install.log` so you can close your terminal and leave but the installer will keep on going on the server. And log back in and look at `install.log` to see progress.\n\n```bash\nnohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 addon -vvv | tee install.log &\n```\n\n**NOTE: If the installer fails, run the getAllRec.sh script to check if common services is up or not. If it isn't up, you can run the installer again. If it is up but one of the capabilities failed tyo get pushed, then that capability can be applied individually** \n## Uninstalling Common Services\n\nIn case the installer fails on the same step multiple times, it's better to uninstall and try again. To uninstall\n\n```bash\nnohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 uninstall-with-openshift | tee install.log &\n```\n\n\n","type":"Mdx","contentDigest":"35a064d8aae021136a3e3cccf0b9e318","counter":241,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"VMware using Offline Images","weight":400},"exports":{},"rawBody":"---\ntitle: VMware using Offline Images\nweight: 400\n---\n\n- [Setting the max_map_count](#setting-the-max_map_count)\n- [Download and extract the image](#download-and-extract-the-image)\n- [Creating config.yaml](#creating-configyaml)\n- [Creating getAllRec.sh](#creating-getallrecsh)\n- [Starting the install process](#starting-the-install-process)\n- [Creating the correct kubeconfig](#creating-the-correct-kubeconfig)\n- [Uninstalling Common Services](#uninstalling-common-services)\n\n**NOTE: Make sure you have 200GB or more on your installer node. If you have less, then you can download the offline image, extract and delete the original file**\n\n## Setting the max_map_count\n\nSSH into all your worker and storage nodes and set the max_map_count to 262144.\n\n```bash\nsudo sysctl -w vm.max_map_count=262144\necho \"vm.max_map_count=262144\" | sudo tee -a /etc/sysctl.conf\n```\n\n## Download and extract the image\n\nSSH into your installer node. Go to `/opt` dir and download the image there. To download the image from IBM XL, use this <https://w3-03.ibm.com/software/xl/download/ticket.wss>. If in the csplab environment, CP4I 2019.4.1 is already downloaded on the csplab jump server, we'll `wget` from there as it's much faster.\n\n```bash\ncd /opt\nwget http://storage4.csplab.local/storage/cp4i/ibm-cp-int-2019.4.1-offline.tar.gz\nmkdir cp4ioffline\ntar xf ibm-cp-int-2019.4.1-offline.tar.gz --directory /opt/cp4ioffline\ncd cp4ioffline\ntar xvf installer_files/cluster/images/common-services-armonk-x86_64.tar.gz -O | sudo docker load\n```\n\nyou can delete `ibm-cp-int-2019.4.1-offline.tar.gz` now if you're low on space.\n\n## Creating config.yaml\n\nFind your oauth route. Run the following command to find it.\n\n```bash\n$ oc get routes --all-namespaces | grep oauth\nopenshift-authentication   oauth-openshift     oauth-openshift.apps.mislam.ocp.csplab.local\n```\n\nGet the config.yaml from here: https://github.ibm.com/cpat/cp4-integration/blob/master/infra/helper-scripts/config.yaml\n\nCreate a backup of the default `config.yaml` inside of `/opt/cp4ioffline/installer_files/cluster` and paste in your oauth route in the following part of your `config.yaml`:\n\n```yaml\nroks_enabled: true\nroks_url: https://oauth-openshift.apps.mnb.ocp.csplab.local -> your oauth route\nroks_user_prefix: \"\"\n```\n\n## Creating getAllRec.sh\n\nWhen the installer fails, this script will echo all the pods that are up and running and pods that are failing.\n\n```bash\ncd /opt\ntouch getAllRec.sh\nsudo chmod 755 getAllRec.sh\n./getAllRec.sh kube-system\n```\n\nGet the getAllRec.sh file from here: https://github.ibm.com/cpat/cp4-integration/blob/master/infra/helper-scripts/getAllRec.sh\n\n## Creating the correct kubeconfig\n\nFirst we have to copy our kubeconfig to the cluster directory. \n\n```bash\ncd /opt/cp4ioffline/installer_files/cluster\noc config view > kubeconfig\n```\n\nNow `cat` your kubeconfig file and see if it has `insecure-skip-tls-verify: true`config. The cluster part should look something like this.\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://api.mislam.ocp.csplab.local:6443\n  name: api-mislam-ocp-csplab-local:6443\n```\n\nBut if you see this, you have to replace `certificate-authority-data: DATA+OMITTED` with `insecure-skip-tls-verify: true`\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: DATA+OMITTED\n    server: https://api.mislam.ocp.csplab.local:6443\n```\n\nAlternatively we can copy it from our Openshift Cluster Auth directory to here. \n\n```bash\ncp /opt/myocpcluster/auth/kubeconfig /opt/cp4ioffline/installer_files/cluster\n```\n\n## Starting the install process\n\nNow we run the installer. Notice it's a nohup job (runs on the background) and the logs are written to `install.log` so you can close your terminal and leave but the installer will keep on going on the server. And log back in and look at `install.log` to see progress.\n\n```bash\nnohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 addon -vvv | tee install.log &\n```\n\n**NOTE: If the installer fails, run the getAllRec.sh script to check if common services is up or not. If it isn't up, you can run the installer again. If it is up but one of the capabilities failed tyo get pushed, then that capability can be applied individually** \n## Uninstalling Common Services\n\nIn case the installer fails on the same step multiple times, it's better to uninstall and try again. To uninstall\n\n```bash\nnohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 uninstall-with-openshift | tee install.log &\n```\n\n\n","fileAbsolutePath":"/home/travis/build/ibm-cloud-architecture/cloudpak8s/src/pages/integration/onprem-offline/index.mdx"}}}}